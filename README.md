# face_eye_tracking

## 集中度の公式
* C = wc1 + (1-w)c2
* c1: 頻度に変換し正規化した瞬き集中度
* c2: 頻度に変換し正規化した顔の動き集中度
* w:  正面からの角度
## 頻度の式
* 回数/時間
## 正規化の式
* (list[i] - max(list)) / (min(list) - max(list)
## wの式
* w = 0 (r = 0, p = 0, y = 0)
* w = 1 - ((r/tr + p/tp + y/ty) / 3)
* r: roll
* p: pitch
* y: yaw
* tn: nの閾値
* r,p,yは動画の1フレーム目でキャリブレーション


## 検討すべきこと
* 何をして集中度を計算するのか?
  * 動画の視聴で集中度を計算する
  * typingで集中度を計算する
  * ほか思いつかない…
  
* 集中度の計算はこれで良いのか？
  * 今更だけど顔の向きじゃなくなってんだけど…
    * 向きの数値は取れるけど, 思ったものよりも範囲が狭い
    * この範囲から出た場合と、向きの数値が一定値より上回ったらよそ見としている
  * 顔の変化量の特徴点は顔の向きの数値を得るときの6点のみで変化量を出している
    * 全部の顔の点を取るべきか
    * よそ見したときにこの点は取れないけど良いのか？

* グラフとかにするべきか？
  * まだグラフ化等はしてない
  * 途中経過をグラフにしても意味がない？
    * 瞬きはどうグラフ化するの？
    * 顔の動きの変化量はフレーム単位で見てるけど, 点が取れない位置に顔が動いたらデータが取れてない
    * よそ見したフレーム数しか見てない
  
* ソンさんの研究とどうつなげるか?
  * typingで集中度を測るの？
  
  
## 改善すべきこと
* wを正面向いた際の1フレームを基準に回転度数の変化を向き？とする
* c2はフェードアウトしたらそもそも測れなくし、その間の集中度を無条件で0にする
* c1の回数は頻度に変換し, c2の移動量も頻度に変換
* 5秒おきに瞬き回数を頻度に変える

## アンケートどうするの？
* 今日中にデータを取る環境を作る必要がある
* アンケート内容
  * どのくらい動画に興味・関心を持ちましたか？ 1〜5段階
  
  
## 生成するjson
* 〰cv.json
  * 1フレーム枚の情報を画像から抜き出した未加工データ
* 〰conc.json
  * 5秒おきのデータに加工して出した集中度のデータ